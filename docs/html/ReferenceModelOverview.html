<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<p><img src="../img/banner.jpg" title="banner" alt="alt text" /></p>
<h1 id="reference-model-overview">4. Reference Model Overview <a id="referencemodel"></a></h1>
<p>This section provides an overview of the reference model, which is an implementation of each of the components in the framework.</p>
<p>There are four sub-sections which cover the usage and internal processes of each of the reference components;</p>
<ul>
<li><strong><a href="CoreComponents.html">4.1 Core components</a></strong></li>
<li><strong><a href="OutputComponents.html">4.2 Output components</a></strong></li>
<li><strong><a href="DataConversionComponents.html">4.3 Data conversion components</a></strong></li>
<li><strong><a href="StreamConversionComponents.html">4.4 Stream conversion components</a></strong></li>
</ul>
<p>The set of <strong><a href="CoreComponents.html">core components</a></strong> provided in this release is as follows;</p>
<ul>
<li><strong>eve</strong> is the event distributing utility. Based on the number of events in the input and the number of processes specified as a parameter, eve outputs subsets of the events as a stream. The output streams into getmodel.</li>
<li><strong>getmodel</strong> generates a stream of effective damageability cdfs for the input stream of events. It generates cdfs from the model files eventfootprint.bin and vulnerability.bin, and the user's exposures file which is called items.bin. getmodel streams into gulcalc or can be output to a binary file.</li>
<li><strong>gulcalc</strong> performs the ground up loss sampling calculations and numerical integration. The output is a stream of sampled ground up losses. This can be output to a binary file or streamed into fmcalc or summarycalc.</li>
<li><strong>fmcalc</strong> performs the insured loss calculations on the ground up loss samples, mean, and total insured value. The output is a stream of insured loss samples. The result can be output to a binary file or streamed into summarycalc.</li>
<li><strong>summarycalc</strong> performs a summing of sampled losses according to the user's reporting requirements. For example this might involve summing coverage losses to regional level, or policy losses to portfolio level. The output is sampled loss by event_id and summary_id, which represents a meaningful group of losses to the user.</li>
</ul>
<p>The standard input and standard output data streams for the core components are covered in the Specification.</p>
<p>Figure 1 shows the core components workflow and the required data input files.</p>
<h5 id="figure-1.-core-components-workflow-and-required-data">Figure 1. Core components workflow and required data</h5>
<p><img src="../img/ktoolsrequireddata.jpg" title="Core workflow and required data" alt="alt text" /></p>
<p>The model <strong>static</strong> data for the core workflow, shown as red source files, are the event footprint, vulnerability, damage bin dictionary and random number file. These are stored in the <strong>'static'</strong> sub-directory of the working folder.</p>
<p>The user / analysis <strong>input</strong> data for the core workflow, shown as blue source files, are the events, items, coverages, fm programme, fm policytc, fm profile, fm xref, fm summary xref and gul summary xref files. These are stored in the <strong>'input'</strong> sub-directory of the working folder.</p>
<p>These are all Oasis kernel format data objects with prescribed formats. Note that the events are a user input rather than a static input because the user could choose to run a subset of the full list of events, or even just one event. Usually, though, the whole event set will be run.</p>
<p>The <strong><a href="OutputComponents.html">output components</a></strong> are various implementations of outputcalc, as described in general terms in the <a href="Specification.html">Specification</a>. The results are written directly into csv file as there is no downstream processing.</p>
<ul>
<li><strong>eltcalc</strong> generates an event loss table from the sampled losses from summarycalc. It contains sample mean and standard deviation, and total exposed value for each event at the given summary level.</li>
<li><strong>leccalc</strong> generates loss exceedance curve from the sampled losses from summarycalc. There are 8 variants of curves with small differences in the output format but the common output fields are summary_id, return period, and loss exceedance threshold. This output is only available for models which provide an occurrence file.</li>
<li><strong>pltcalc</strong> generates a period loss table from the sampled losses from summarycalc. It contains sample mean and standard deviation, and total exposed value for each event and each period (for example a year) at the given summary level. It also contains a date field, corresponding to the date of the event occurrence. This output is only available for models which provide an occurrence file.</li>
<li><strong>aalcalc</strong> and <strong>aalsummary</strong> generate the average annual loss and standard deviation of loss from the sampled losses from summarycalc, for each summary_id. The output also contains total exposed value for each summary level, which is the maximum of the total exposed value across all simulated periods. This output is only available for models which provide an occurrence file.</li>
</ul>
<p>The files required for the output components are shown in Figure 2.</p>
<h5 id="figure-2.-output-workflows-and-required-data">Figure 2. Output workflows and required data</h5>
<p><img src="../img/outputsrequireddata.jpg" title="Output workflows and required data" alt="alt text" /></p>
<p>The <strong><a href="DataConversionComponents.html">data conversion components</a></strong> section covers the formats of all of the required data files and explains how to convert data in csv format into binary format, and vice versa.</p>
<p>Finally, the <strong><a href="StreamConversionComponents.html">stream conversion components</a></strong> section explains how to convert the binary data stream output to csv, plus how to convert gulcalc data in csv format into binary format. These components are useful when working with individual components at a more detailed level.</p>
<p>The version of the installed components can be found by using the command line parameter -v. For example;</p>
<pre><code>$ gulcalc -v</code></pre>
<p>The components have additional command line parameters depending on their particular function. These are described in detail in the following pages.</p>
<p><a href="#referencemodel">Return to top</a></p>
<p><a href="CoreComponents.html">Go to 4.1 Core Components section</a></p>
<p><a href="Contents.html">Back to Contents</a></p>
</body>
</html>
